import logging
import threading
import time
import traceback
from typing import Dict, Generator, List, Optional, Tuple

import gradio as gr

from src.config import ModelConfigManager
from src.dao.documents import DocumentDAO
from src.llm.context import ContextManager
from src.llm.llm import LocalBaseLLM, RagRobotLLM
from src.llm.prompt import PromptManager
from src.rag.document_store import DocumentStore
from src.rag.rag_chain import RagChain
from src.rag.retriever import DocumentRetriever

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

rag_robot_llm = None
current_template = None
current_model = None
rag_chain = None


def get_all_templates() -> List[Dict]:
    """è·å–æ‰€æœ‰æç¤ºè¯æ¨¡æ¿

    Returns:
        List[Dict]: æ¨¡æ¿åˆ—è¡¨
    """
    try:
        templates = PromptManager().list_templates()
        logger.debug(f"è·å–åˆ° {len(templates)} ä¸ªæç¤ºè¯æ¨¡æ¿")
        return templates
    except Exception as e:
        logger.error(f"è·å–æç¤ºè¯æ¨¡æ¿æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return []


def get_template_choices() -> Tuple[List[Tuple[str, str]], Optional[str]]:
    """è·å–æç¤ºè¯æ¨¡æ¿é€‰é¡¹å’Œé»˜è®¤é€‰é¡¹

    Returns:
        Tuple[List[Tuple[str, str]], Optional[str]]: æ¨¡æ¿é€‰é¡¹åˆ—è¡¨å’Œé»˜è®¤é€‰é¡¹
    """
    templates = get_all_templates()
    if not templates:
        return [], None

    # ä½¿ç”¨å…ƒç»„åˆ—è¡¨æ ¼å¼ [(æ˜¾ç¤ºæ–‡æœ¬, å€¼), ...]
    choices = [
        (
            f"{template['id']}: {template['name']}",
            f"{template['id']}: {template['name']}",
        )
        for template in templates
    ]

    # æ‰¾å‡ºIDæœ€å°çš„æ¨¡æ¿ä½œä¸ºé»˜è®¤é€‰é¡¹
    min_id_template = min(templates, key=lambda x: x["id"])
    default_choice = f"{min_id_template['id']}: {min_id_template['name']}"

    return choices, default_choice


def get_all_models() -> List[Dict]:
    """è·å–æ‰€æœ‰æ¨¡å‹é…ç½®

    Returns:
        List[Dict]: æ¨¡å‹åˆ—è¡¨
    """
    try:
        model_config_manager = ModelConfigManager()
        model_config_manager.load()
        models = model_config_manager.models
        logger.debug(f"è·å–åˆ° {len(models)} ä¸ªæ¨¡å‹é…ç½®")
        return models
    except Exception as e:
        logger.error(f"è·å–æ¨¡å‹é…ç½®æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return []


def get_model_choices() -> Tuple[List[Tuple[str, str]], Optional[str]]:
    """è·å–æ¨¡å‹é€‰é¡¹å’Œé»˜è®¤é€‰é¡¹

    Returns:
        Tuple[List[Tuple[str, str]], Optional[str]]: æ¨¡å‹é€‰é¡¹åˆ—è¡¨å’Œé»˜è®¤é€‰é¡¹
    """
    models = get_all_models()
    if not models:
        return [], None

    # ä½¿ç”¨å…ƒç»„åˆ—è¡¨æ ¼å¼ [(æ˜¾ç¤ºæ–‡æœ¬, å€¼), ...]
    choices = [(model.name, model.name) for model in models]

    # é»˜è®¤é€‰æ‹©llama3.2æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰åˆ™é€‰æ‹©ç¬¬ä¸€ä¸ª
    default_choice = next(
        (choice[0] for choice in choices if "llama3.2" in choice[0].lower()),
        choices[0][0] if choices else None,
    )

    return choices, default_choice


def create_rag_robot_llm(
    template_id: int = 1, model_name: str = "llama3.2:latest"
) -> RagRobotLLM:
    """åˆ›å»ºRagRobotLLMå®ä¾‹

    Args:
        template_id: æç¤ºè¯æ¨¡æ¿IDï¼Œé»˜è®¤ä¸º1
        model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸ºllama3.2:latest

    Returns:
        RagRobotLLM: RagRobotLLMå®ä¾‹
    """
    try:
        # è·å–æ¨¡å‹é…ç½®
        logger.info("æ­£åœ¨è·å–æ¨¡å‹é…ç½®...")
        model_config_manager = ModelConfigManager()
        model_config_manager.load()
        model_config = model_config_manager.get_model(model_name)

        if not model_config:
            logger.error(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_name}")
            raise ValueError(f"No model configuration found for {model_name}")

        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_config.name}")

        # åˆ›å»ºLLMå®ä¾‹
        logger.info("æ­£åœ¨åˆ›å»ºLLMå®ä¾‹...")
        llm = LocalBaseLLM(model=model_config)

        # åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
        logger.info(f"æ­£åœ¨åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä½¿ç”¨æ¨¡æ¿ID: {template_id}...")
        context_manager = ContextManager(
            prompt_manager=PromptManager(),
            template_id=template_id,
            max_history_length=10,
        )

        # åˆ›å»ºRagRobotLLMå®ä¾‹
        logger.info("æ­£åœ¨åˆ›å»ºRagRobotLLMå®ä¾‹...")
        return RagRobotLLM(context_manager=context_manager, llm=llm)
    except Exception as e:
        logger.error(f"åˆ›å»ºRagRobotLLMå®ä¾‹æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        raise


def create_rag_chain(template_id: int = 1, model_name: str = "llama3.2:latest"):
    """åˆ›å»ºRAGé“¾"""
    retriever = DocumentRetriever(DocumentStore())
    rag_chain = RagChain(
        retriever=retriever, template_id=template_id, model_name=model_name
    )
    return rag_chain


def stream_chat(message: str, history, docs_retriever):
    """æµå¼å¯¹è¯å‡½æ•°

    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        history: å¯¹è¯å†å²

    Returns:
        Generator: ç”Ÿæˆå™¨ï¼Œç”¨äºæµå¼è¿”å›å“åº”
    """
    global rag_robot_llm, rag_chain
    try:
        logger.info(f"ç”¨æˆ·è¾“å…¥: {message}")

        # ç”Ÿæˆå“åº”
        partial_message = ""
        par_docs_message = ""
        ok = False
        for chunk in rag_chain.stream(message):
            if chunk == "[end]":
                ok = True
                continue
            if not ok:
                partial_message += chunk
                history[-1][1] = partial_message
                yield history, docs_retriever
            else:
                par_docs_message += chunk
                docs_retriever = par_docs_message
                yield history, docs_retriever

        logger.info(f"AIå“åº”å®Œæˆ: {partial_message[:100]}...")
    except Exception as e:
        logger.error(f"æµå¼å¯¹è¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        history[-1][1] = f"å¯¹è¯å‡ºé”™: {str(e)}"
        yield history, docs_retriever


def clear_history():
    """æ¸…é™¤å¯¹è¯å†å²

    Returns:
        list: ç©ºçš„èŠå¤©å†å²åˆ—è¡¨
    """
    global rag_robot_llm
    try:
        logger.info("æ¸…é™¤å¯¹è¯å†å²")
        rag_robot_llm.clear_history()
        return [], ""
    except Exception as e:
        logger.error(f"æ¸…é™¤å¯¹è¯å†å²æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return [], ""


def change_template(template_choice: str):
    """æ›´æ”¹æç¤ºè¯æ¨¡æ¿

    Args:
        template_choice: æ¨¡æ¿é€‰é¡¹ï¼Œæ ¼å¼ä¸º"id: name"

    Returns:
        list: ç©ºçš„èŠå¤©å†å²åˆ—è¡¨ï¼Œå› ä¸ºæ›´æ¢æ¨¡æ¿åéœ€è¦æ¸…é™¤å†å²
    """
    global rag_robot_llm, current_template, current_model
    try:
        if not template_choice or template_choice == current_template:
            return []

        # ä»é€‰é¡¹ä¸­æå–æ¨¡æ¿ID
        template_id = int(template_choice.split(":")[0])
        logger.info(f"æ›´æ”¹æç¤ºè¯æ¨¡æ¿ä¸ºID: {template_id}")

        # æ›´æ–°RagRobotLLMå®ä¾‹çš„æ¨¡æ¿
        rag_robot_llm.context_manager.change_template(template_id)

        # æ›´æ–°å½“å‰æ¨¡æ¿
        current_template = template_choice

        # æ¸…é™¤å†å²è®°å½•
        return []
    except Exception as e:
        logger.error(f"æ›´æ”¹æç¤ºè¯æ¨¡æ¿æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return []


def change_model(model_choice: str):
    """æ›´æ”¹æ¨¡å‹

    Args:
        model_choice: æ¨¡å‹é€‰é¡¹ï¼Œå³æ¨¡å‹åç§°

    Returns:
        list: ç©ºçš„èŠå¤©å†å²åˆ—è¡¨ï¼Œå› ä¸ºæ›´æ¢æ¨¡å‹åéœ€è¦æ¸…é™¤å†å²
    """
    global rag_robot_llm, current_model, current_template
    try:
        if not model_choice or model_choice == current_model:
            return []

        # æ›´æ–°å½“å‰æ¨¡å‹
        logger.info(f"æ›´æ”¹æ¨¡å‹ä¸º: {model_choice}")

        # æå–å½“å‰æ¨¡æ¿ID
        template_id = 1
        if current_template and ":" in current_template:
            template_id = int(current_template.split(":")[0])

        # é‡æ–°åˆ›å»ºRagRobotLLMå®ä¾‹
        rag_robot_llm = create_rag_robot_llm(
            template_id=template_id, model_name=model_choice
        )
        current_model = model_choice

        # æ¸…é™¤å†å²è®°å½•
        return []
    except Exception as e:
        logger.error(f"æ›´æ”¹æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return []


def update_template_dropdown():
    """æ›´æ–°æ¨¡æ¿ä¸‹æ‹‰èœå•"""
    templates = get_all_templates()
    choices = [
        (
            f"{template['id']}: {template['name']}",
            f"{template['id']}: {template['name']}",
        )
        for template in templates
    ]
    return gr.Dropdown(choices=choices)


def update_model_dropdown():
    """æ›´æ–°æ¨¡å‹ä¸‹æ‹‰èœå•"""
    models = get_all_models()
    choices = [(model.name, model.name) for model in models]
    return gr.Dropdown(choices=choices)


def main():
    """ä¸»å‡½æ•°"""
    global rag_robot_llm, current_template, current_model, rag_chain
    try:
        logger.info("å¯åŠ¨RAG Robotå¯¹è¯ç³»ç»Ÿ...")

        # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨
        logger.info("æ­£åœ¨åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨...")

        # è·å–åˆå§‹æ¨¡æ¿é€‰é¡¹
        template_choices, default_template = get_template_choices()
        current_template = default_template

        # è·å–åˆå§‹æ¨¡å‹é€‰é¡¹
        model_choices, default_model = get_model_choices()
        current_model = default_model

        # åˆ›å»ºRagRobotLLMå®ä¾‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿ID
        logger.info("æ­£åœ¨åˆ›å»ºRagRobotLLMå®ä¾‹...")
        default_template_id = (
            int(current_template.split(":")[0]) if current_template else 1
        )
        model_name = "llama3.2:latest"  # é»˜è®¤æ¨¡å‹
        if current_model:
            model_name = current_model
        rag_robot_llm = create_rag_robot_llm(
            template_id=default_template_id, model_name=model_name
        )
        rag_chain = create_rag_chain(
            template_id=default_template_id, model_name=model_name
        )

        # åˆ›å»ºGradioç•Œé¢
        logger.info("æ­£åœ¨åˆ›å»ºGradioç•Œé¢...")
        with gr.Blocks(title="RAG Robot å¯¹è¯ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
            gr.Markdown("# RAG Robot å¯¹è¯ç³»ç»Ÿ")
            gr.Markdown("è¿™æ˜¯ä¸€ä¸ªåŸºäºRAGæŠ€æœ¯çš„å¯¹è¯ç³»ç»Ÿï¼Œå¯ä»¥è¿›è¡Œæµå¼å¯¹è¯ã€‚")

            # æ·»åŠ æ¨¡å‹å’Œæ–‡æ¡£é€‰æ‹©ä¸‹æ‹‰èœå•
            with gr.Row():
                template_dropdown = gr.Dropdown(
                    label="é€‰æ‹©æç¤ºè¯æ¨¡æ¿",
                    choices=template_choices,
                    value=current_template,
                    interactive=True,
                )
                model_dropdown = gr.Dropdown(
                    label="é€‰æ‹©æ¨¡å‹",
                    choices=model_choices,
                    value=current_model,
                    interactive=True,
                    scale=1,
                )

            chatbot = gr.Chatbot(
                height=600,
                show_copy_button=True,
                # avatar_images=[(None, "ğŸ‘¤"), (None, "ğŸ¤–")],
                bubble_full_width=False,
            )

            with gr.Row():
                msg = gr.Textbox(
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                    container=False,
                    scale=9,
                    autofocus=True,
                )
                submit_btn = gr.Button("å‘é€", scale=1, variant="primary")

            with gr.Row():
                clear_btn = gr.Button("æ¸…é™¤å¯¹è¯å†å²")
                refresh_btn = gr.Button("åˆ·æ–°ä¸‹æ‹‰èœå•")

            with gr.Row():
                docs_retriever = gr.Markdown()

            # è®¾ç½®äº‹ä»¶å¤„ç†
            logger.info("æ­£åœ¨è®¾ç½®äº‹ä»¶å¤„ç†...")
            msg2 = gr.Textbox(visible=False)
            submit_btn.click(
                fn=lambda message, history: (
                    "",
                    history + [[message, ""]],
                    message,
                    "",
                ),
                inputs=[msg, chatbot],
                outputs=[msg, chatbot, msg2, docs_retriever],
                queue=False,
            ).then(
                fn=stream_chat,
                inputs=[msg2, chatbot, docs_retriever],
                outputs=[chatbot, docs_retriever],
                queue=True,
            )

            msg.submit(
                fn=lambda message, history: (
                    "",
                    history + [[message, ""]],
                    message,
                    "",
                ),
                inputs=[msg, chatbot],
                outputs=[msg, chatbot, msg2, docs_retriever],
                queue=False,
            ).then(
                fn=stream_chat,
                inputs=[msg2, chatbot, docs_retriever],
                outputs=[chatbot, docs_retriever],
                queue=True,
            )

            clear_btn.click(
                fn=clear_history,
                inputs=[],
                outputs=[chatbot, docs_retriever],
                queue=False,
            )

            # æ·»åŠ æ¨¡æ¿é€‰æ‹©äº‹ä»¶å¤„ç†
            template_dropdown.change(
                fn=change_template,
                inputs=[template_dropdown],
                outputs=[chatbot],
                queue=False,
            )

            # æ·»åŠ æ¨¡å‹é€‰æ‹©äº‹ä»¶å¤„ç†
            model_dropdown.change(
                fn=change_model,
                inputs=[model_dropdown],
                outputs=[chatbot],
                queue=False,
            )

            # æ·»åŠ åˆ·æ–°æŒ‰é’®äº‹ä»¶å¤„ç†
            refresh_btn.click(
                fn=update_template_dropdown,
                inputs=[],
                outputs=[template_dropdown],
                queue=False,
            ).then(
                fn=update_model_dropdown,
                inputs=[],
                outputs=[model_dropdown],
                queue=False,
            )

            # # è®¾ç½®å®šæ—¶åˆ·æ–°
            # demo.load(
            #     fn=update_template_dropdown,
            #     inputs=[],
            #     outputs=[template_dropdown],
            #     every=0.1  # æ¯10ç§’åˆ·æ–°ä¸€æ¬¡
            # )

            # demo.load(
            #     fn=update_model_dropdown,
            #     inputs=[],
            #     outputs=[model_dropdown],
            #     every=0.1  # æ¯10ç§’åˆ·æ–°ä¸€æ¬¡
            # )

            # åœ¨åº”ç”¨å…³é—­æ—¶åœæ­¢åˆ·æ–°ç®¡ç†å™¨
            def on_close():
                logger.info("æ­£åœ¨å…³é—­RefreshManager...")

            demo.close = on_close

        # å¯åŠ¨Gradioåº”ç”¨
        logger.info("æ­£åœ¨å¯åŠ¨Gradioåº”ç”¨...")
        demo.queue()
        demo.launch(server_name="0.0.0.0", share=False)
        logger.info("Gradioåº”ç”¨å·²å¯åŠ¨")
    except Exception as e:
        logger.error(f"å¯åŠ¨RAG Robotå¯¹è¯ç³»ç»Ÿæ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    main()
