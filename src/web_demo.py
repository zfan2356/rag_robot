import logging
import traceback
from typing import Generator

import gradio as gr

from src.config import ModelConfigManager
from src.llm.context import ContextManager
from src.llm.llm import LocalBaseLLM, RagRobotLLM
from src.llm.prompt import PromptManager

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

PROMPT_TEMPLATE_ID = 1
# å…¨å±€å˜é‡ï¼Œå­˜å‚¨RagRobotLLMå®ä¾‹
rag_robot_llm = None


def create_rag_robot_llm(template_id: int = 1) -> RagRobotLLM:
    """åˆ›å»ºRagRobotLLMå®ä¾‹

    Args:
        template_id: æç¤ºè¯æ¨¡æ¿IDï¼Œé»˜è®¤ä¸º1

    Returns:
        RagRobotLLM: RagRobotLLMå®ä¾‹
    """
    try:
        # è·å–æ¨¡å‹é…ç½®
        logger.info("æ­£åœ¨è·å–æ¨¡å‹é…ç½®...")
        model_config_manager = ModelConfigManager()
        model_config_manager.load()
        model_config = model_config_manager.get_model("llama3.2:latest")

        if not model_config:
            logger.error("æœªæ‰¾åˆ°æ¨¡å‹é…ç½®")
            raise ValueError("No model configuration found")

        logger.info(f"ä½¿ç”¨æ¨¡å‹: {model_config.name}")

        # åˆ›å»ºLLMå®ä¾‹
        logger.info("æ­£åœ¨åˆ›å»ºLLMå®ä¾‹...")
        llm = LocalBaseLLM(model=model_config)

        # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨
        logger.info("æ­£åœ¨åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨...")
        prompt_manager = PromptManager()

        # åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
        logger.info(f"æ­£åœ¨åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä½¿ç”¨æ¨¡æ¿ID: {PROMPT_TEMPLATE_ID}...")
        context_manager = ContextManager(
            prompt_manager=prompt_manager,
            template_id=PROMPT_TEMPLATE_ID,
            max_history_length=10,
        )

        # åˆ›å»ºRagRobotLLMå®ä¾‹
        logger.info("æ­£åœ¨åˆ›å»ºRagRobotLLMå®ä¾‹...")
        return RagRobotLLM(context_manager=context_manager, llm=llm)
    except Exception as e:
        logger.error(f"åˆ›å»ºRagRobotLLMå®ä¾‹æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        raise


def stream_chat(message: str, history) -> Generator:
    """æµå¼å¯¹è¯å‡½æ•°

    Args:
        message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        history: å¯¹è¯å†å²

    Returns:
        Generator: ç”Ÿæˆå™¨ï¼Œç”¨äºæµå¼è¿”å›å“åº”
    """
    global rag_robot_llm
    try:
        logger.info(f"ç”¨æˆ·è¾“å…¥: {message}")
        partial_message = ""
        for chunk in rag_robot_llm.stream_generate(message):
            partial_message += chunk
            # æ›´æ–°å†å²è®°å½•ä¸­æœ€åä¸€æ¡æ¶ˆæ¯çš„å›å¤éƒ¨åˆ†
            history[-1][1] = partial_message
            yield history
        logger.info(f"AIå“åº”å®Œæˆ: {partial_message[:100]}...")
    except Exception as e:
        logger.error(f"æµå¼å¯¹è¯æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        history[-1][1] = f"å¯¹è¯å‡ºé”™: {str(e)}"
        yield history


def clear_history():
    """æ¸…é™¤å¯¹è¯å†å²

    Returns:
        list: ç©ºçš„èŠå¤©å†å²åˆ—è¡¨
    """
    global rag_robot_llm
    try:
        logger.info("æ¸…é™¤å¯¹è¯å†å²")
        rag_robot_llm.clear_history()
        return []
    except Exception as e:
        logger.error(f"æ¸…é™¤å¯¹è¯å†å²æ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())
        return []


def main():
    """ä¸»å‡½æ•°"""
    global rag_robot_llm
    try:
        logger.info("å¯åŠ¨RAG Robotå¯¹è¯ç³»ç»Ÿ...")

        # åˆ›å»ºRagRobotLLMå®ä¾‹
        logger.info("æ­£åœ¨åˆ›å»ºRagRobotLLMå®ä¾‹...")
        rag_robot_llm = create_rag_robot_llm()

        # åˆ›å»ºGradioç•Œé¢
        logger.info("æ­£åœ¨åˆ›å»ºGradioç•Œé¢...")
        with gr.Blocks(title="RAG Robot å¯¹è¯ç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
            gr.Markdown("# RAG Robot å¯¹è¯ç³»ç»Ÿ")
            gr.Markdown("è¿™æ˜¯ä¸€ä¸ªåŸºäºRAGæŠ€æœ¯çš„å¯¹è¯ç³»ç»Ÿï¼Œå¯ä»¥è¿›è¡Œæµå¼å¯¹è¯ã€‚")

            chatbot = gr.Chatbot(
                height=600,
                show_copy_button=True,
                # avatar_images=[(None, "ğŸ‘¤"), (None, "ğŸ¤–")],
                bubble_full_width=False,
            )

            with gr.Row():
                msg = gr.Textbox(
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                    container=False,
                    scale=9,
                    autofocus=True,
                )
                submit_btn = gr.Button("å‘é€", scale=1, variant="primary")

            with gr.Row():
                clear_btn = gr.Button("æ¸…é™¤å¯¹è¯å†å²")
                template_dropdown = gr.Dropdown(
                    label="é€‰æ‹©æç¤ºè¯æ¨¡æ¿",
                    choices=["é»˜è®¤æ¨¡æ¿"],
                    value="é»˜è®¤æ¨¡æ¿",
                    interactive=True,
                )

            # è®¾ç½®äº‹ä»¶å¤„ç†
            logger.info("æ­£åœ¨è®¾ç½®äº‹ä»¶å¤„ç†...")
            submit_btn.click(
                fn=lambda message, history: ("", history + [[message, ""]]),
                inputs=[msg, chatbot],
                outputs=[msg, chatbot],
                queue=False,
            ).then(
                fn=stream_chat,
                inputs=[msg, chatbot],
                outputs=chatbot,
                queue=True,
            )

            msg.submit(
                fn=lambda message, history: ("", history + [[message, ""]]),
                inputs=[msg, chatbot],
                outputs=[msg, chatbot],
                queue=False,
            ).then(
                fn=stream_chat,
                inputs=[msg, chatbot],
                outputs=chatbot,
                queue=True,
            )

            clear_btn.click(
                fn=clear_history,
                inputs=[],
                outputs=chatbot,
                queue=False,
            )

        # å¯åŠ¨Gradioåº”ç”¨
        logger.info("æ­£åœ¨å¯åŠ¨Gradioåº”ç”¨...")
        demo.queue()
        demo.launch(server_name="0.0.0.0", share=False)
        logger.info("Gradioåº”ç”¨å·²å¯åŠ¨")
    except Exception as e:
        logger.error(f"å¯åŠ¨RAG Robotå¯¹è¯ç³»ç»Ÿæ—¶å‡ºé”™: {str(e)}")
        logger.error(traceback.format_exc())


if __name__ == "__main__":
    main()
